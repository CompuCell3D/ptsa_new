{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Purpose of this notebook:\n",
    "The purpose of this notebook is to familiarize the user with the functionality of the ptsa object TalReader, used to extract out relevant electrode localization arrays, and relevant changes that have been made to it recently.\n",
    "\n",
    "Let's start by importing the TalReader and JsonIndexReader, which allows us to get the relevant path for the TalReader (and EEGReader, BaseEventReader, etc.):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'ptsa'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-1defb57eb3a4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Relevant import line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mptsa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreaders\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mJsonIndexReader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTalReader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'ptsa'"
     ]
    }
   ],
   "source": [
    "# General imports\n",
    "import numpy as np\n",
    "import os, sys\n",
    "\n",
    "# Relevant import line\n",
    "from ptsa.data.readers import JsonIndexReader, TalReader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# There are two ways to access data on \n",
    "\n",
    "1. Mount rhino locally \n",
    "2. Through accessing the cluster directly\n",
    "\n",
    "This is relevant because typically rhino gets mounted at '/Volumes/rhino', which changes precisely where the relevant paths are. Below we'll use the package os in order to check which directory we're in and then adjust are paths using that check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = os.getcwd()\n",
    "local = '' if (cwd.split('/')[1][:4] == 'home') else '/Volumes/rhino'\n",
    "protocol = local + '/protocols/r1.json'\n",
    "\n",
    "# Initalize the json reader by passing it the protocol path\n",
    "jr = JsonIndexReader(protocol)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use JsonIndexReader to get subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('The default output type of JsonIndexReader is', <type 'set'>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False], dtype=bool)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# By default jr.aggregate_values will return a set\n",
    "subjects_set = jr.aggregate_values('subjects',experiment='FR1')\n",
    "print('The default output type of JsonIndexReader is', type(subjects_set))\n",
    "\n",
    "\n",
    "# We can convert it to an array (first cast it as a list, because \n",
    "# Again the output is a set) or simply as a list like below\n",
    "subjects_list = list(subjects_set)\n",
    "\n",
    "\n",
    "# Remember that Arrays of sets are not the same as arrays of lists\n",
    "subjects_arr = np.array(list(jr.aggregate_values('subjects',experiment='FR1')))\n",
    "subjects_arr == np.array(jr.aggregate_values('subjects',experiment='FR1'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# If the user isn't sure of the experiment fields they can input, they can check all possible experiments like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'catFR2',\n",
       " u'PS2.1',\n",
       " u'catFR1',\n",
       " u'catFR6',\n",
       " u'THR',\n",
       " u'catFR5',\n",
       " u'PS5_catFR',\n",
       " u'PS2',\n",
       " u'PS3',\n",
       " u'PS1',\n",
       " u'THR1',\n",
       " u'PAL1',\n",
       " u'YC2',\n",
       " u'YC1',\n",
       " u'PAL2',\n",
       " u'TH3',\n",
       " u'TH1',\n",
       " u'FR3',\n",
       " u'FR2',\n",
       " u'FR1',\n",
       " u'FR6',\n",
       " u'FR5',\n",
       " u'catFR3',\n",
       " u'PAL3',\n",
       " u'PAL5']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If the user isn't sure of the experimental fields they can input, they can check like so:\n",
    "list(jr.aggregate_values('experiments'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False], dtype=bool)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remember that Arrays of sets are not the same as arrays of lists\n",
    "subjects_arr = np.array(list(jr.aggregate_values('subjects',experiment='FR1')))\n",
    "subjects_arr == np.array(jr.aggregate_values('subjects',experiment='FR1'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a Function to Load subject's tal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Functions to load talirach\n",
    "def get_subj_tal(subject, experiment, return_channels=False):\n",
    "    \"\"\"Returns a subject's talairach using TalReader and JsonIndexReader\n",
    "    -----\n",
    "    INPUTS:\n",
    "    -----\n",
    "    subject: str, subject ID, e.g. 'R1111M'\n",
    "    experiment: str, experiment, e.g. 'FR1', 'catFR1'\n",
    "    return_channels: bool, default = False, whether to return arrays of\n",
    "                     monopolar and bipolar channels used for EEGReader\n",
    "    ------\n",
    "    OUTPUTS if return_channels is False:\n",
    "    ------\n",
    "    tal_reader.read(): np.recarray, an array containing relevant values \n",
    "                       for electrode localization\n",
    "    ------\n",
    "    OUTPUTS if return_channels is True:\n",
    "    ------                   \n",
    "    mp: np.recarray, monopolar channels used for EEGReader\n",
    "    bp: np.recarray, bipolar channels used for EEGReader\n",
    "    tal_reader.read(): np.recarray, an array containing relevant values \n",
    "                       for electrode localization\n",
    "    \"\"\"\n",
    "    \n",
    "    # Check if we're using this locally or through rhino directly\n",
    "    cwd = os.getcwd()\n",
    "    local = '' if (cwd.split('/')[1][:4] == 'home') else '/Volumes/rhino'\n",
    "    protocol = local + '/protocols/r1.json'\n",
    "    \n",
    "    # Load the protocol \n",
    "    jr = JsonIndexReader(protocol)\n",
    "    \n",
    "    # Get the path for the TalReader\n",
    "    pairs_path = jr.get_value('pairs', subject=subject, experiment=experiment)\n",
    "    \n",
    "    # Create an instance of the TalReader object\n",
    "    tal_reader = TalReader(filename=pairs_path)\n",
    "    \n",
    "    # If desired, also return the monopolar and bipolar channels\n",
    "    if return_channels:\n",
    "        mp = tal_reader.get_monopolar_channels()\n",
    "        bp = tal_reader.get_bipolar_pairs()\n",
    "        return mp, bp, tal_reader.read()\n",
    "    \n",
    "    # Otherwise just return the tal\n",
    "    return tal_reader.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load a single subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/loganfickling/anaconda/envs/ptsa_testing/lib/python2.7/site-packages/numpy/core/records.py:507: FutureWarning: Numpy has detected that you may be viewing or writing to an array returned by selecting multiple fields in a structured array. \n",
      "\n",
      "This code may break in numpy 1.13 because this will return a view instead of a copy -- see release notes for details.\n",
      "  return obj.view(dtype=(self.dtype.type, obj.dtype))\n"
     ]
    }
   ],
   "source": [
    "subj, exp = subjects_arr[0], 'FR1'\n",
    "\n",
    "mp, bp, tal = get_subj_tal(subject=subj, experiment=exp, return_channels=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by examining the dtype of the array, as we can see TalReader.read() outputs a structured nested record array with relevant information shown below\n",
    "\n",
    "These fields refer to the following:\n",
    "\n",
    "'channel_1' : int, representing the first channel in the bp montage \n",
    "\n",
    "'channel_2' : int, representing the second channel in the bp montage \n",
    "\n",
    "'code' : str, the name of the bipolar channel (e.g. LF1-LF2)\n",
    "\n",
    "'id' : ???\n",
    "\n",
    "'is_explicit' : ???\n",
    "\n",
    "'is_stim_only' : corresponds to the tal_stim_only struct in matlab, means that the channel was only used to stimulate and was not used for recording\n",
    "\n",
    "'type_1' : the type of the first channel in the bp montage (D = Depth, S= Strip, G=Grid)\n",
    "\n",
    "'type_2' : the type of the second channel in the bp montage (D = Depth, S= Strip, G=Grid)\n",
    "\n",
    "'atlases' : numpy.record.array, an array of possible brain atlases to use for the subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "example bipolar channel:\n",
      "\n",
      "(1, 2, u'1LD1-1LD2', u'1ld.1-1ld.2', False, False, u'D', u'D', ((u'avg', u'None', -16.785, -13.85, -17.675), (u'avg.dural', u'None', -16.785, -13.85, -17.675), (u'das', u'CA1', nan, nan, nan), (u'ind', u'None', -18.665, 13.495, -19.995), (u'ind.dural', u'None', -18.665, 13.495, -19.995), (u'stein', u'Left CA1', nan, nan, nan), (u'tal', u'None', -17.60525, -8.807725, -15.891), (u'wb', u'Left Hippocampus', nan, nan, nan)))\n",
      "\n",
      "dtype names:\n",
      "\n",
      "('channel_1', 'channel_2', 'code', 'id', 'is_explicit', 'is_stim_only', 'type_1', 'type_2', 'atlases')\n"
     ]
    }
   ],
   "source": [
    "print('example bipolar channel:\\n')\n",
    "print(tal[0])\n",
    "\n",
    "print('\\ndtype names:\\n')\n",
    "print(tal.dtype.names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to access localization information we refer to the field 'atlases', which has the following atlases associated with it:\n",
    "\n",
    "| Name | Description |\n",
    "| --- | --- |\n",
    "| `avg` | localization in average subject space (Freesurfer space?)|\n",
    "| `avg.dural` |localization in average subject space whereby each electrode is snapped to the closest cortical surface (Freesurfer space?)|\n",
    "| `das` | localization done by Sandy (similiar to stein but done by sandy) |\n",
    "| `ind` | localization in individual subject space (Freesurfer space?) |\n",
    "| `ind.dural` | localization in individual subject space whereby each electrode is snapped to the closest cortical surface (Freesurfer space?) |\n",
    "| `stein` | localization done by joel stein, analgous to old TalReader's locTag field |\n",
    "| `tal` | localization in talairach space \n",
    "| `wb` | localization in mni wholebrain |\n",
    "| `dk` | ?? <- Not all subjects have this? |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('avg', 'avg.dural', 'das', 'ind', 'ind.dural', 'stein', 'tal', 'wb')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show the atlases we can look at\n",
    "tal['atlases'].dtype.names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's choose to look at the individual subject atlas, but the following fields should be associated with each atlas:\n",
    "\n",
    "| Name | Description |\n",
    "| --- | --- |\n",
    "| `id` | refers to the atlas id, for example the 'tal' atlas has id 'tal', 'avg' has id 'avg' etc. |\n",
    "| `region` | what region in the brain the electrode is in |\n",
    "| `x` | x coordinate of electrode |\n",
    "| `y` | y coordinate of electrode |\n",
    "| `z` | z coordinate of electrode |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('id', 'region', 'x', 'y', 'z')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fields we can access inside this atlas\n",
    "tal['atlases']['ind'].dtype.names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can quickly manipulate our data using this array\n",
    "\n",
    "## Getting all coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_coords(tal, atlas):\n",
    "    \"\"\"Returns the coordinates of the associated atlas for the tal array\"\"\"\n",
    "    coords = np.vstack((tal['atlases'][atlas]['x'], \n",
    "                        tal['atlases'][atlas]['y'], \n",
    "                        tal['atlases'][atlas]['z'])).T\n",
    "    return coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('ind', array([[-18.665,  13.495, -19.995],\n",
      "       [-23.495,  12.92 , -20.92 ],\n",
      "       [-28.32 ,  12.345, -21.845],\n",
      "       [-33.395,  11.29 , -22.705],\n",
      "       [-38.47 ,  10.235, -23.565]]))\n",
      "('avg:', array([[-16.785, -13.85 , -17.675],\n",
      "       [-22.255, -14.48 , -18.34 ],\n",
      "       [-27.72 , -15.105, -19.   ],\n",
      "       [-33.465, -16.23 , -19.525],\n",
      "       [-39.215, -17.36 , -20.05 ]]))\n",
      "('stein:', array([[ nan,  nan,  nan],\n",
      "       [ nan,  nan,  nan],\n",
      "       [ nan,  nan,  nan],\n",
      "       [ nan,  nan,  nan],\n",
      "       [ nan,  nan,  nan]]))\n",
      "('tal:', array([[-17.60525 ,  -8.807725, -15.891   ],\n",
      "       [-23.0165  ,  -9.52845 , -16.38325 ],\n",
      "       [-28.4278  , -10.24916 , -16.8755  ],\n",
      "       [-34.1166  , -11.46135 , -17.2087  ],\n",
      "       [-39.8053  , -12.67355 , -17.54185 ]]))\n"
     ]
    }
   ],
   "source": [
    "print('ind', get_coords(tal, 'ind')[:5])\n",
    "\n",
    "print('avg:', get_coords(tal, 'avg')[:5])\n",
    "\n",
    "print('stein:', get_coords(tal, 'stein')[:5])\n",
    "\n",
    "print('tal:', get_coords(tal, 'tal')[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting all regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([u'Left CA1', u'Left Amy', u'Left CA1', u'nan', u'nan', u'nan',\n",
       "       u'nan', u'nan', u'Left Middle Temporal Gyrus', u'Left MTL WM',\n",
       "       u'Left CA1', u'Left DG', u'nan', u'nan', u'nan', u'nan',\n",
       "       u'Left Middle Temporal Gyrus', u'Left Middle Temporal Gyrus',\n",
       "       u'Right Amy', u'Right Amy', u'nan', u'nan', u'nan', u'nan', u'nan',\n",
       "       u'nan', u'Right DG', u'Right CA1', u'nan', u'nan', u'nan', u'nan',\n",
       "       u'Right CA1', u'Right CA1', u'nan', u'nan', u'nan', u'nan', u'nan',\n",
       "       u'Right MTL WM', u'Right CA1', u'Right CA1', u'nan', u'nan', u'nan',\n",
       "       u'nan', u'Right Middle Temporal Gyrus',\n",
       "       u'Right Middle Temporal Gyrus', u'nan', u'nan', u'nan', u'nan',\n",
       "       u'nan', u'nan', u'nan', u'nan', u'nan', u'nan', u'nan', u'nan',\n",
       "       u'Right Middle Temporal Gyrus', u'nan', u'nan', u'nan', u'nan',\n",
       "       u'nan', u'nan', u'nan', u'nan', u'nan', u'nan', u'nan', u'nan',\n",
       "       u'nan', u'nan'],\n",
       "      dtype='<U256')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tal['atlases']['stein']['region']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check hemisphere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Left', 'Left', 'Left', 'Left', 'Left', 'Left', 'Left', 'Left',\n",
       "       'Left', 'Left', 'Left', 'Left', 'Left', 'Left', 'Left', 'Left',\n",
       "       'Left', 'Left', 'Right', 'Right', 'Right', 'Right', 'Right',\n",
       "       'Right', 'Right', 'Right', 'Right', 'Right', 'Right', 'Right',\n",
       "       'Right', 'Right', 'Right', 'Right', 'Right', 'Right', 'Right',\n",
       "       'Right', 'Right', 'Right', 'Right', 'Right', 'Right', 'Right',\n",
       "       'Right', 'Right', 'Right', 'Right', 'Right', 'Right', 'Right',\n",
       "       'Right', 'Right', 'Right', 'Right', 'Right', 'Right', 'Right',\n",
       "       'Right', 'Right', 'Right', 'Right', 'Right', 'Right', 'Right',\n",
       "       'Right', 'Right', 'Right', 'Right', 'Right', 'Right', 'Right',\n",
       "       'Right', 'Right', 'Right'],\n",
       "      dtype='|S5')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def check_hemi(tal, atlas='ind'):\n",
    "    return np.array(['Left' if x ==-1. else 'Right' for x in np.sign(tal['atlases'][atlas]['x'])])\n",
    "\n",
    "check_hemi(tal=tal)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
